{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: MultibandMRI 0.1.0\n",
      "Uninstalling MultibandMRI-0.1.0:\n",
      "  Successfully uninstalled MultibandMRI-0.1.0\n",
      "Collecting git+https://github.com/AdaptiveMRILab/MultibandMRI.git\n",
      "  Cloning https://github.com/AdaptiveMRILab/MultibandMRI.git to /private/var/folders/30/x3_16p4d5j5cq5v20dn6smqm0000gq/T/pip-req-build-vp4vcr3z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/AdaptiveMRILab/MultibandMRI.git /private/var/folders/30/x3_16p4d5j5cq5v20dn6smqm0000gq/T/pip-req-build-vp4vcr3z\n",
      "  Resolved https://github.com/AdaptiveMRILab/MultibandMRI.git to commit 9a11aaec251dffdb4e74b31ce28f50270ec28939\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: MultibandMRI\n",
      "  Building wheel for MultibandMRI (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for MultibandMRI: filename=MultibandMRI-0.1.0-py3-none-any.whl size=8251 sha256=85f323e7554cf2c257ff0fff2193c2ec4cdbac01d7692d6aaad78b2b4555a929\n",
      "  Stored in directory: /private/var/folders/30/x3_16p4d5j5cq5v20dn6smqm0000gq/T/pip-ephem-wheel-cache-7k7vfncl/wheels/54/cc/03/f5b8e399de4023fd079a1dbf0b918dbad6f0787e62b15802b9\n",
      "Successfully built MultibandMRI\n",
      "Installing collected packages: MultibandMRI\n",
      "Successfully installed MultibandMRI-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall -y MultibandMRI \n",
    "!pip3 install git+https://github.com/AdaptiveMRILab/MultibandMRI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import h5py \n",
    "import matplotlib.pyplot as plt \n",
    "from MultibandMRI import slice_grappa, split_slice_grappa, sense_grappa, fft1d, fft2d, ifft1d, ifft2d\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "calibration_datapath = '/Users/nmickevicius/data/20250115_three_band_CMT/20250115_10_12_03_CMT_2D/_Series_0000/recon.h5'\n",
    "aliased_datapath = '/Users/nmickevicius/data/20250115_three_band_CMT/20250115_10_19_18_CMT_2D/_Series_0000/recon.h5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Calibration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_calib_lines = 16\n",
    "\n",
    "# these datasets were acquired with three contrasts \n",
    "# specify here which one to use \n",
    "contrast = 2\n",
    "\n",
    "# fetch the k-space from the h5 file \n",
    "with h5py.File(calibration_datapath,'r') as F:\n",
    "    ksp = np.array(F['ksp'], dtype=np.complex64)[:,:,:,0,contrast]\n",
    "ksp = torch.tensor(ksp, dtype=torch.complex64, device=device)\n",
    "\n",
    "# extract each slice from the extended POMP FOV\n",
    "img = ifft2d(ksp, dims=(0,1))\n",
    "img = torch.stack([img[:,:128,:], img[:,128:256,:],img[:,256:,:]], axis=-1)\n",
    "data = fft2d(img, dims=(0,1))\n",
    "\n",
    "# add CAIPI shifts to calibration data \n",
    "data[:,1::3,:,0] = data[:,1::3,:,0] * np.exp(1j*2*np.pi/3)\n",
    "data[:,2::3,:,0] = data[:,2::3,:,0] * np.exp(1j*4*np.pi/3)\n",
    "data[:,1::3,:,2] = data[:,1::3,:,2] * np.exp(-1j*2*np.pi/3)\n",
    "data[:,2::3,:,2] = data[:,2::3,:,2] * np.exp(-1j*4*np.pi/3)\n",
    "\n",
    "# crop to the desired number of calibration lines\n",
    "i1 = int(data.shape[1]/2 - num_calib_lines/2)\n",
    "i2 = i1 + num_calib_lines \n",
    "calib_data = data[:,i1:i2,...]\n",
    "calib_data = calib_data.permute(3,2,0,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate the Kernels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sg = slice_grappa(calib_data, accel=(1,1), kernel_size=(3,3), tik=1e-4, final_matrix_size=(128,128))\n",
    "spsg = split_slice_grappa(calib_data, accel=(1,1), kernel_size=(3,3), tik=1e-4, final_matrix_size=(128,128))\n",
    "rosg = sense_grappa(calib_data, accel=(1,1), kernel_size=(4,3), tik=1e-4, final_matrix_size=(128,128))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128, 32])\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(aliased_datapath,'r') as F:\n",
    "    aliased_ksp = np.array(F['ksp'], dtype=np.complex64)[:,:,:,0,contrast]\n",
    "aliased_ksp = torch.tensor(aliased_ksp, dtype=torch.complex64, device=device)\n",
    "aliased_ksp = aliased_ksp.permute(2,0,1)[None,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_sg, rss_sg = sg.apply(aliased_ksp)\n",
    "ksp_spsg, rss_spsg = spsg.apply(aliased_ksp)\n",
    "ksp_rosg, rss_rosg = rosg.apply(aliased_ksp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrix_mri_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
