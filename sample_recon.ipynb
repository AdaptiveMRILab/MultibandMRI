{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd354101",
   "metadata": {},
   "source": [
    "# How to use reconstruction toolbox:\n",
    "\n",
    "**To use the reconstruction toolbox:**  \n",
    "\n",
    "**1.)** Download the repository to a local directory.  \n",
    "**2.)** In this file, scroll to the \"User Inputs\" section and look at the \"FILEPATH SETUP\" section.  \n",
    "**3.)** Fill in the sms_folder and raki_recon_folder with the \"data\" and \"model_folder\" filepaths, respectively.  \n",
    "**4.)** In the \"GPU ACCELERATION\" section, input your PyTorch device of choice, GPU is highly recommended.  \n",
    "**5.)** Look through the other values within the \"USER INPUT\" section and adjust as desired.  \n",
    "**6.)** Select \"Run All\" in the notebook.  \n",
    "\n",
    "**To apply the reconstructions to your own data in this notebook:**  \n",
    "\n",
    "**1.)** Save your calibration (POMP) data and accelerated (blipped-CAIPI) kspace data as h5 files in a folder titled \"SMS_N\", where N is equal to the SMS factor. Partial POMP should work with this code, given that the num_calib_lines or in_plane_acs_sizes do not exceed that of the collected lines. This code currently does not work for multiple collections of SMS factors, so only one kspace dataset per SMS factor will work.  \n",
    "**2.)** If multiple SMS factors are collected, they will need to be in the same folder. This folder's filepath should be set to the \"sms_folder\" variable.  \n",
    "**3.)** Go through the \"USER INPUT\" section and tweak any reconstruction parameters as desired. \n",
    "\n",
    "**Otherwise:**  \n",
    "\n",
    "You can just look at the function calls in the \"Image Reconstruction\" section of this notebook and look at the functions themselves in the MultibandMRI repository to apply or tweak the code based on your specifications and needs. At the bare minimum, you can call the functions like so:\n",
    "\n",
    "\\# Call the class (automatically does the calibration)  \n",
    "obj = slice_grappa(calibration_data) \\# Replace with any function of your choice  \n",
    "\n",
    "\\# Apply the grappa by calling the apply function  \n",
    "kspace, _ = slice_grappa.apply(accelerated_data)  \n",
    "\n",
    "We encourage you to look at the functions themselves to see what parameters you can pass into the functions. All possible parameters that can be passed into the functions are done so as a part of this reconstruction notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e9e48",
   "metadata": {},
   "source": [
    "# Install MultibandMRI module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 uninstall -y MultibandMRI \n",
    "!pip3 install git+https://github.com/AdaptiveMRILab/MultibandMRI.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a4176",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dfc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np \n",
    "import torch \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from MultibandMRI import slice_grappa, split_slice_grappa, sense_grappa, slice_raki, split_slice_raki, sense_raki, ifft2d, fft2d, CoilCompress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538d9dd",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd35365",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#       GPU ACCELERATION       #\n",
    "################################\n",
    "\n",
    "# \"device\" will be where the compuations will take place, this may change depending on your device\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "################################\n",
    "#        FILE PATH SETUP       #\n",
    "################################\n",
    "\n",
    "# The filepath that contains the SMS data\n",
    "# String should be along the lines of: \"/{filepath-to-repository}/multiband_mri/data\"\n",
    "sms_folder = '/{filepath-to-repository}/multiband_mri/data'\n",
    "\n",
    "# The path that contains RAKI models\n",
    "# String should be along the lines of: \"/{filepath-to-repository}/multiband_mri/model_folder\"\n",
    "raki_recon_folder = '/{filepath-to-repository}/multiband_mri/model_folder'\n",
    "\n",
    "################################\n",
    "#       COIL COMPRESSION       #\n",
    "################################\n",
    "\n",
    "# A flag that will determine whether or not coil compression occurs\n",
    "# Possible options: True / False\n",
    "coil_compression = True\n",
    "\n",
    "# The number of coils after compression\n",
    "# Accepted values = Integers less than 32\n",
    "ncoils = 16\n",
    "\n",
    "################################\n",
    "#     RECONSTRUCTION TYPES     #\n",
    "################################\n",
    "\n",
    "# A list of all SMS factors to be reconstructed\n",
    "# Accepted values = [2, 3, 4, 5]\n",
    "sms_factors = [2, 3, 4, 5]\n",
    "\n",
    "# A list of all GRAPPA recon types to complete\n",
    "# Can be empty, will only perform RAKI if that is the case\n",
    "# Possible options: 'slice-grappa', 'split-slice-grappa', 'sense-grappa'\n",
    "grappa_recon_types = ['slice-grappa', 'split-slice-grappa', 'sense-grappa']\n",
    "\n",
    "# A list of all RAKI recon types to complete\n",
    "# Can be empty, will only perform GRAPPA if that is the case\n",
    "# Possible options: 'slice-raki', 'split-slice-raki', 'sense-raki'\n",
    "raki_recon_types = ['slice-raki', 'split-slice-raki', 'sense-raki']\n",
    "\n",
    "################################\n",
    "#   RECONSTRUCTION PARAMETERS  #\n",
    "################################\n",
    "\n",
    "# List of number of calibration lines used to calculate kernels\n",
    "# Accepted values: Positive integer values less than 256\n",
    "num_calib_lines = [48]\n",
    "\n",
    "# List of all retrospective in-plane acceleration factors \n",
    "# Accepted values: Positive, non-zero integers\n",
    "in_plane_acceleration_factors = [1, 2]\n",
    "\n",
    "# Number of ACS lines used in accelerated datasets (retrospective)\n",
    "# Can be a list, but recommended to be a singular value, as the code is not optimized for multiple entries\n",
    "in_plane_acs_sizes = [0]\n",
    "\n",
    "# List of all readout kernel sizes to try \n",
    "# Accepted values: Odd values (will become even if appropriate (i.e. SENSE-GRAPPA))\n",
    "readout_kernel_size = [5]\n",
    "\n",
    "# List of phase kernel sizes \n",
    "# Accepted values: Odd values (will become even if appropriate (i.e. SENSE-GRAPPA))\n",
    "phase_kernel_size = [5] \n",
    "\n",
    "################################\n",
    "#       GRAPPA PARAMETERS      #\n",
    "################################\n",
    "\n",
    "# List of tikhonov regularization parameters\n",
    "# Accepted values: Greater than or equal to zero\n",
    "tik_values = [0.0]\n",
    "\n",
    "################################\n",
    "#        RAKI PARAMETERS       #\n",
    "################################\n",
    "\n",
    "# List of network types 'MLP' or 'RES' \n",
    "# 'MLP' - complex-valued fully connected multi-layer network\n",
    "# 'RES' - complex-valued residual network with fully connected layers\n",
    "#         (if 'RES' is selected, num_layers will be the number of residual blocks,\n",
    "#          which themselves each have three fully-connected layers)\n",
    "# Adding a 'b' to the end of the net_type (i.e. 'MLPb' or 'RESb') will use complex \n",
    "#         b-splines instead of the complex ReLU that is typically used\n",
    "net_types = ['MLP']\n",
    "\n",
    "# List of number of layers to use \n",
    "# Accepted values: Positive ingeters\n",
    "num_layers = [3]\n",
    "\n",
    "# List of number of nuerons per hidden layer in the CNN\n",
    "# Accepted values: Positive ingeters\n",
    "hidden_sizes = [128]\n",
    "\n",
    "# List of the number of epochs to try\n",
    "# Accepted values: Positive ingeters\n",
    "num_epochs = [500]\n",
    "\n",
    "# List of training/validation data splits\n",
    "# Accepted values: Between zero and one, excluding zero and one\n",
    "train_splits = [0.9]\n",
    "\n",
    "# Flexible tradeoff between zero (no residual RAKI) and one (residual RAKI)\n",
    "# Instead of learning residual flags, this allows a more flexible tradeoff \n",
    "#   between linear reconstruction and RAKI reconstruction\n",
    "# Accepted values: Between zero and one, including zero and one\n",
    "linear_weights = [0.0]\n",
    "\n",
    "# List of L1/L2 loss tradeoff values\n",
    "# Accepted values: Between zero and one, including zero and one\n",
    "# 0.0 = L1 loss\n",
    "# 1.0 = L2 loss (MSE loss)\n",
    "# 0.0 < value < 1.0 is a weighted sum of L1 and L2\n",
    "l1_l2_tradeoff_values = [0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b0f9f",
   "metadata": {},
   "source": [
    "# Load in Data and Show Reference Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all data (keep on cpu until it is needed)\n",
    "\n",
    "# Initialize data arrays\n",
    "calib_data = []\n",
    "accel_data = []\n",
    "ref_images = []\n",
    "\n",
    "# Loops over SMS factors\n",
    "for sms in sms_factors:\n",
    "\n",
    "    # Gets the calibration datapath for each SMS factor\n",
    "    calibfile = os.path.join(sms_folder, 'SMS_%i'%(sms), 'ksp_calib.h5')\n",
    "\n",
    "    # Load the calibration data from the filepath\n",
    "    with h5py.File(calibfile,'r') as F:\n",
    "        ksp_calib = torch.tensor(np.array(F['ksp'][...,0], dtype=np.complex64), dtype=torch.complex64, device=torch.device('cpu'))\n",
    "\n",
    "    # Gets the frequency encode array size\n",
    "    N = ksp_calib.shape[0]\n",
    "\n",
    "    # # Used for showing coil compressed reference images\n",
    "    # # Comment in to look at reference images with coil compression\n",
    "    # # DO NOT run the reconstructions with these lines commented in and coil compression on\n",
    "    # if coil_compression:\n",
    "        \n",
    "    #     # Modifies the kspace to be compatible with CoilCompress class\n",
    "    #     ksp_calib = ksp_calib.permute(2,0,1)\n",
    "    #     ksp_calib = ksp_calib.unsqueeze(0)\n",
    "\n",
    "    #     # Computes the coil compression\n",
    "    #     coilCompress = CoilCompress(ksp_calib,ncoils)\n",
    "\n",
    "    #     # Applies the coil compression\n",
    "    #     ksp_calib = coilCompress.compress(ksp_calib)\n",
    "\n",
    "    #     # Reverts the kspace to the same shape as before coil compression\n",
    "    #     ksp_calib = ksp_calib.squeeze(0)\n",
    "    #     ksp_calib = ksp_calib.permute(1,2,0)\n",
    "\n",
    "    # Final matrix size is square, matching that of the frequency encode array size\n",
    "    final_matrix_size = (N,N)\n",
    "\n",
    "    # Shift POMP FOVs for even SMS factors\n",
    "    if sms%2 == 0:\n",
    "        phi = 2 * np.pi / (2 * sms)\n",
    "        for p in range(2*sms):\n",
    "            ksp_calib[:,p::(2*sms),:] = ksp_calib[:,p::(2*sms),:] * np.exp(-1j * p * phi)\n",
    "\n",
    "    # Bring to extended phase FOV (POMP) image space \n",
    "    img = ifft2d(ksp_calib, dims=(0,1))\n",
    "\n",
    "    # Shifts the image so slices furthest from isocenter appear first and slice at isocenter appears last\n",
    "    isocenter_slice = sms//2\n",
    "    nshift = (sms - isocenter_slice - 1) * N \n",
    "    img = torch.roll(img, shifts=nshift, dims=1) \n",
    "\n",
    "    # Extract each slice from the extended POMP FOV\n",
    "    img = torch.stack([img[:,(n*N):((n+1)*N),:] for n in range(sms)], axis=-1)\n",
    "\n",
    "    # Flip so that slice position increases with index \n",
    "    img = torch.flip(img, dims=(-1,))\n",
    "\n",
    "    # Shows the reference images\n",
    "    rss = torch.sqrt(torch.sum(torch.abs(img * img.conj()),dim=2))\n",
    "    fig, ax = plt.subplots(1,sms)\n",
    "    fig.set_figwidth(3*sms)\n",
    "    for n in range(sms):\n",
    "        ax[n].imshow(rss[:,:,n].cpu(), cmap='gray')\n",
    "        ax[n].set_xticks([])\n",
    "        ax[n].set_yticks([])\n",
    "        ax[n].set_title('Reference Slice %i'%(n))\n",
    "    plt.show()\n",
    "\n",
    "    # Brings the data back to k-space\n",
    "    data = fft2d(img, dims=(0,1))\n",
    "\n",
    "    # Add CAIPI shifts to calibration data \n",
    "    blip_phase_increment = 2 * np.pi / sms \n",
    "    for slc in range(sms):\n",
    "        for p in range(sms):\n",
    "            data[:,p::sms,:,slc] = data[:,p::sms,:,slc] * np.exp(1j*blip_phase_increment*slc*p)\n",
    "\n",
    "    # Re-arrange the data \n",
    "    data = data.permute(3,2,0,1)\n",
    "\n",
    "    # Saves the fully sampled kspace as calibration_data\n",
    "    calib_data.append(data.clone())\n",
    "\n",
    "    # Saves the reference images as ref_images\n",
    "    ref_images.append(img.clone())\n",
    "\n",
    "    # Gets the SMS accelerated datapath\n",
    "    accelfile = os.path.join(sms_folder, 'SMS_%i'%(sms), 'ksp_accel.h5')\n",
    "\n",
    "    # Load the accelerated data from the filepath\n",
    "    with h5py.File(accelfile,'r') as F:\n",
    "        aliased_ksp = np.array(F['ksp'], dtype=np.complex64)[:,:,:,0]\n",
    "\n",
    "    # Puts the aliased k-space onto the cpu\n",
    "    aliased_ksp = torch.tensor(aliased_ksp, dtype=torch.complex64, device=torch.device('cpu'))\n",
    "\n",
    "    # Rearranges kspace shape to work with functions\n",
    "    aliased_ksp = aliased_ksp.permute(2,0,1)[None,...]\n",
    "\n",
    "    # Saves the SMS accelerated kspace as accel_data\n",
    "    accel_data.append(aliased_ksp.clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae562c57",
   "metadata": {},
   "source": [
    "# Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops over all in plane acceleration factors\n",
    "for rip in in_plane_acceleration_factors:\n",
    "\n",
    "    # Loops over all number of calibration lines\n",
    "    for ncal in num_calib_lines:\n",
    "\n",
    "        # Loops over all combinations of entered kernel sizes\n",
    "        for rks in readout_kernel_size:\n",
    "            for pks in phase_kernel_size:\n",
    "\n",
    "                # Loops over all SMS factors\n",
    "                for sms in sms_factors:\n",
    "\n",
    "                    # Transfer calibration data to GPU-accelerated device for current SMS factor\n",
    "                    data_cal = calib_data[sms_factors.index(sms)].clone().to(device)\n",
    "\n",
    "                    # Compresses the coil count to ncoils (from 32), if desired\n",
    "                    if coil_compression:\n",
    "                        data_cal_tmp = torch.sum(data_cal, dim=0, keepdim=True)\n",
    "                        coilCompress = CoilCompress(data_cal_tmp,ncoils)\n",
    "                        data_cal = coilCompress.compress(data_cal)\n",
    "\n",
    "                    # Crop the calibration data to be the desired number of calibration lines\n",
    "                    i1 = int(data_cal.shape[-1]/2 - ncal/2)\n",
    "                    i2 = i1 + ncal \n",
    "                    data_cal = data_cal[...,i1:i2]\n",
    "\n",
    "                    # Sets the acceleration for GRAPPA/RAKI functions to use\n",
    "                    accel = (1, rip)\n",
    "                    \n",
    "                    #################\n",
    "                    # GRAPPA recons #\n",
    "                    #################\n",
    "\n",
    "                    # Loops over all GRAPPA recon types\n",
    "                    for recon_name in grappa_recon_types:\n",
    "\n",
    "                        # Loops over all GRAPPA-specific parameters \n",
    "\n",
    "                        # Loops over all entered Tikhonov regularization values\n",
    "                        for tik in tik_values:\n",
    "\n",
    "                            # Loops over all other reconstruction parameters\n",
    "\n",
    "                            # Loops over number of ACS lines\n",
    "                            for nacs in in_plane_acs_sizes:\n",
    "\n",
    "                                # Determines the best kernel size depending on the current algorithm and then calibrates for the algorithm\n",
    "                                if recon_name == 'sense-grappa':\n",
    "                                    kernel_size = (2*(rks//2), pks if rip == 1 else 2*(pks//2))\n",
    "                                    obj = sense_grappa(data_cal, accel=accel, kernel_size=kernel_size, tik=tik, final_matrix_size=final_matrix_size)\n",
    "                                elif recon_name == 'slice-grappa':\n",
    "                                    kernel_size = (rks, pks if rip == 1 else 2*(pks//2))\n",
    "                                    obj = slice_grappa(data_cal, accel=accel, kernel_size=kernel_size, tik=tik, final_matrix_size=final_matrix_size)\n",
    "                                elif recon_name == 'split-slice-grappa':\n",
    "                                    kernel_size = (rks, pks if rip == 1 else 2*(pks//2))\n",
    "                                    obj = split_slice_grappa(data_cal, accel=accel, kernel_size=kernel_size, tik=tik, final_matrix_size=final_matrix_size)\n",
    "\n",
    "                                # Transfer accelerated data to device for current SMS factor\n",
    "                                data_acc = accel_data[sms_factors.index(sms)].clone().to(device)\n",
    "\n",
    "                                # Compresses the coil count to ncoils, (from 32) if desired\n",
    "                                if coil_compression == True:\n",
    "                                    data_acc = coilCompress.compress(data_acc)\n",
    "\n",
    "                                # Get the ACS data\n",
    "                                if nacs > 0:\n",
    "                                    i1 = int(aliased_ksp.shape[-1]/2 - nacs/2)\n",
    "                                    i2 = i1 + nacs \n",
    "                                    acs_data = data_acc[...,i1:i2].clone()\n",
    "\n",
    "                                # Retrospective in-plane acceleration\n",
    "                                for n in range(1,rip):\n",
    "                                    data_acc[...,n::rip] = 0.0\n",
    "\n",
    "                                # Put central ACS lines back into array\n",
    "                                if nacs > 0:\n",
    "                                    data_acc[...,i1:i2] = acs_data \n",
    "\n",
    "                                # Applies the reconstruction!\n",
    "                                ksp_recon, _ = obj.apply(data_acc)\n",
    "\n",
    "                                # Frees up GPU memory\n",
    "                                del obj\n",
    "\n",
    "                                # Remove CAIPI shifts from reconstructed data\n",
    "                                blip_phase_increment = 2 * np.pi / sms \n",
    "                                for slc in range(sms):\n",
    "                                    for p in range(sms):\n",
    "                                        ksp_recon[slc,:,:,p::sms] = ksp_recon[slc,:,:,p::sms] * np.exp(-1j*blip_phase_increment*slc*p) # [slice, coil, kx, ky]\n",
    "                                \n",
    "                                # Brings the data into the image domain\n",
    "                                img_recon = ifft2d(ksp_recon, dims=(2,3))\n",
    "                                img_recon = torch.sqrt(torch.sum(torch.abs(img_recon * img_recon.conj()), dim=1))\n",
    "\n",
    "                                # Plots the GRAPPA reconstructions\n",
    "                                fig, ax = plt.subplots(1,sms)\n",
    "                                fig.set_figwidth(3*sms)\n",
    "                                for n in range(sms):\n",
    "                                    ax[n].imshow(img_recon[n,:,:].cpu(), cmap='gray')\n",
    "                                    ax[n].set_xticks([])\n",
    "                                    ax[n].set_yticks([])\n",
    "                                fig.suptitle('SMS=%i, R=%i, nacs=%i, ksize=%s, ncal=%i, λ=%.2E, %s'%(sms, rip, nacs, kernel_size, ncal, tik, recon_name))\n",
    "                                fig.tight_layout()\n",
    "                                plt.show()\n",
    "\n",
    "                                # Breaks out of the ACS loop if there is multiple ACS values for in-plane acceleration of 1 to save time\n",
    "                                if rip == 1: break\n",
    "\n",
    "                    ########################\n",
    "                    # RAKI reconstructions #\n",
    "                    ########################\n",
    "                                \n",
    "                    # Loops over all RAKI recon types\n",
    "                    for recon_name in raki_recon_types:\n",
    "\n",
    "                        # Loops over all RAKI-secpific parameters\n",
    "\n",
    "                        # Loops over all desired values of linear weight(residual RAKI)\n",
    "                        for linear_weight in linear_weights:\n",
    "\n",
    "                            # Loops over all desired values of epochs\n",
    "                            for epochs in num_epochs:\n",
    "\n",
    "                                # Loops over all desired values of number of neural network layers\n",
    "                                for nlayers in num_layers:\n",
    "\n",
    "                                    # Loops over all desired values of neurons per layer\n",
    "                                    for hsize in hidden_sizes:\n",
    "\n",
    "                                        # Loops over all desired values of training / validation splits\n",
    "                                        for train_split in train_splits:\n",
    "\n",
    "                                            # Loops over all desired L1/L2 regularization values\n",
    "                                            for l2_frac in l1_l2_tradeoff_values:\n",
    "\n",
    "                                                # Loops over all desired network types\n",
    "                                                for net_type in net_types:\n",
    "\n",
    "                                                    # Loops over all other reconstruction parameters\n",
    "\n",
    "                                                    # Loops over number of ACS lines  \n",
    "                                                    for nacs in in_plane_acs_sizes:\n",
    "\n",
    "                                                        # Determines the best kernel size depending on the current algorithm and then conducts the neural network training\n",
    "                                                        if recon_name == 'sense-raki':\n",
    "                                                            kernel_size = (2*(rks//2), pks if rip == 1 else 2*(pks//2))\n",
    "                                                            obj = sense_raki(data_cal, raki_recon_folder, accel=accel, kernel_size=kernel_size, final_matrix_size=final_matrix_size,\n",
    "                                                                                linear_weight=linear_weight, num_epochs=epochs, num_layers=nlayers, hidden_size=hsize, train_split=train_split,\n",
    "                                                                                loss_function='L1_L2', l2_frac=l2_frac, net_type=net_type)\n",
    "                                                        elif recon_name == 'slice-raki':\n",
    "                                                            kernel_size = (rks, pks if rip == 1 else 2*(pks//2))\n",
    "                                                            obj = slice_raki(data_cal, raki_recon_folder, accel=accel, kernel_size=kernel_size, final_matrix_size=final_matrix_size,\n",
    "                                                                                linear_weight=linear_weight, num_epochs=epochs, num_layers=nlayers, hidden_size=hsize, train_split=train_split,\n",
    "                                                                                loss_function='L1_L2', l2_frac=l2_frac, net_type=net_type)\n",
    "                                                        elif recon_name == 'split-slice-raki':\n",
    "                                                            kernel_size = (rks, pks if rip == 1 else 2*(pks//2))\n",
    "                                                            obj = split_slice_raki(data_cal, raki_recon_folder, accel=accel, kernel_size=kernel_size, final_matrix_size=final_matrix_size,\n",
    "                                                                                linear_weight=linear_weight, num_epochs=epochs, num_layers=nlayers, hidden_size=hsize, train_split=train_split,\n",
    "                                                                                loss_function='L1_L2', l2_frac=l2_frac, net_type=net_type)\n",
    "\n",
    "                                                        # Transfer accelerated data to device for current SMS factor\n",
    "                                                        data_acc = accel_data[sms_factors.index(sms)].clone().to(device)\n",
    "\n",
    "                                                        # Compresses the coil count to ncoils, (from 32) if desired\n",
    "                                                        if coil_compression == True:\n",
    "                                                            data_acc = coilCompress.compress(data_acc)\n",
    "\n",
    "                                                        # Get the ACS data\n",
    "                                                        if nacs > 0:\n",
    "                                                            i1 = int(aliased_ksp.shape[-1]/2 - nacs/2)\n",
    "                                                            i2 = i1 + nacs \n",
    "                                                            acs_data = data_acc[...,i1:i2].clone()\n",
    "\n",
    "                                                        # Retrospective in-plane acceleration\n",
    "                                                        for n in range(1,rip):\n",
    "                                                            data_acc[...,n::rip] = 0.0\n",
    "\n",
    "                                                        # Put central ACS lines back into array\n",
    "                                                        if nacs > 0:\n",
    "                                                            data_acc[...,i1:i2] = acs_data \n",
    "\n",
    "                                                        # Applies the reconstruction!\n",
    "                                                        ksp_recon, _ = obj.apply(data_acc)\n",
    "\n",
    "                                                        # Frees up GPU memory\n",
    "                                                        del obj\n",
    "\n",
    "                                                        # Remove CAIPI shifts from reconstructed data\n",
    "                                                        blip_phase_increment = 2 * np.pi / sms \n",
    "                                                        for slc in range(sms):\n",
    "                                                            for p in range(sms):\n",
    "                                                                ksp_recon[slc,:,:,p::sms] = ksp_recon[slc,:,:,p::sms] * np.exp(-1j*blip_phase_increment*slc*p)\n",
    "                                                        \n",
    "                                                        # Brings the data into the image domain\n",
    "                                                        img_recon = ifft2d(ksp_recon, dims=(2,3))\n",
    "                                                        img_recon = torch.sqrt(torch.sum(torch.abs(img_recon * img_recon.conj()), dim=1))\n",
    "\n",
    "                                                        # Plots the RAKI reconstructions\n",
    "                                                        fig, ax = plt.subplots(1,sms)\n",
    "                                                        fig.set_figwidth(3*sms)\n",
    "                                                        for n in range(sms):\n",
    "                                                            ax[n].imshow(img_recon[n,:,:].cpu(), cmap='gray')\n",
    "                                                            ax[n].set_xticks([])\n",
    "                                                            ax[n].set_yticks([])\n",
    "                                                        fig.suptitle('SMS=%i, R=%i, nacs=%i, ksize=%s, ncal=%i, lin. weight=%f, l1/l2=%f, epochs=%i, layers=%i, hsize=%i, %s, %s' % \\\n",
    "                                                                    (sms, rip, nacs, kernel_size, ncal, linear_weight, l2_frac, epochs, nlayers, hsize, recon_name, net_type))\n",
    "                                                        fig.tight_layout()\n",
    "                                                        plt.show()\n",
    "\n",
    "                                                        # Breaks out of the ACS loop if there is multiple ACS values for in-plane acceleration of 1 to save time\n",
    "                                                        if rip == 1: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
